name: Test
# Edit the `test.yml` in `.github/workflows/templates` and run `make_workflows.py` to update the
# workflow.

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  pull_request:
      types: [opened, labeled, reopened, synchronize]

  # Trigger on pushes to the trunk branches. This prevents building commits twice when the pull
  # request source branch is in the same repository.
  push:
    branches:
    - "trunk-*"

  # Trigger on request.
  workflow_dispatch:


env:
  # prevent deadlocked MPI tests from causing the job to cancel
  MPIEXEC_TIMEOUT: 3000
  # allow mpirun to execute as root in the tests
  OMPI_ALLOW_RUN_AS_ROOT: 1
  OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
  # allow openmpi to oversubscribe cores
  OMPI_MCA_rmaps_base_oversubscribe: 1
  # prevent errors from mis-configured openib systems
  OMPI_MCA_btl: "vader,self"
  # skip running the CPU tests in GPU builds
  _HOOMD_SKIP_CPU_TESTS_WHEN_GPUS_PRESENT_: 1
  # import HOOMD out of the build directory
  PYTHONPATH: ${{ github.workspace }}/install


# Use multiple jobs to reduce the amount of time spent on GPU runners. Use CPU runners for
# compiling all tests configurations (GPU and CPU), then upload the build directory (sans object
# files) as an artifact. Test jobs depend on the build job, download the install directory, and run
# the tests. Upload each build configuration to a separate artifact.

# Github Actions does not support any form of templating at this time, not even YAML anchors.
# To minimize the number of duplicated lines, encode the job configuration as an array in config:
# [image, (mpi), (tbb)]
jobs:
  start_action_runners:
    name: Start action runners
    runs-on: ubuntu-latest
    steps:
    - name: Use jetstream2-admin/start
      uses: glotzerlab/jetstream2-admin/start@v1.2.2
      with:
        OS_APPLICATION_CREDENTIAL_ID: ${{ secrets.OS_APPLICATION_CREDENTIAL_ID }}
        OS_APPLICATION_CREDENTIAL_SECRET: ${{ secrets.OS_APPLICATION_CREDENTIAL_SECRET }}

  build:
    name: Build [${{ join(matrix.config, '_') }}]
    runs-on: ${{ matrix.build_runner }}
    container:
      image: glotzerlab/ci:2023.05-${{ matrix.config[0] }}
    strategy:
      matrix:
        include:
        - {config: [clang14_py311, mpi, tbb, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nomd], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nohpmc], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nomd, nohpmc], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [cuda120_gcc11_py310, mpi, llvm, debug], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda120_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda120_gcc11_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [gcc9_py39], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }

    steps:
    - name: Set Werror on recent compilers
      run: |
        echo "CXXFLAGS=-Werror" >> $GITHUB_ENV
      if: ${{ !startsWith(matrix.config[0], 'gcc7') }}
    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Checkout
      uses: actions/checkout@v3.5.2
      with:
        path: code
        submodules: true

    - name: Configure
      run: |
        mkdir -p build
        cd build
        if [[ ${BUILD_DEBUG} == "true" ]]; then BUILD_TYPE="Debug"; else BUILD_TYPE="Release"; fi
        echo "BUILD_TYPE=${BUILD_TYPE}"
        cmake ../code -GNinja \
                      -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \
                      -DENABLE_GPU=${ENABLE_GPU:-"OFF"} \
                      -DENABLE_MPI=${ENABLE_MPI:-"OFF"} \
                      -DENABLE_TBB=${ENABLE_TBB:-"OFF"} \
                      -DENABLE_LLVM=${ENABLE_LLVM:-"OFF"} \
                      -DBUILD_MD=${BUILD_MD:-"ON"} \
                      -DBUILD_MPCD=${BUILD_MD:-"ON"} \
                      -DBUILD_METAL=${BUILD_MD:-"ON"} \
                      -DBUILD_HPMC=${BUILD_HPMC:-"ON"} \
                      -DCUDA_ARCH_LIST="60;70" \
                      -DENABLE_DEBUG_JIT=ON \
                      -DCMAKE_INSTALL_PREFIX=${GITHUB_WORKSPACE}/install \
                      -DPLUGINS=""
      env:
        ENABLE_GPU: ${{ contains(matrix.config[0], 'cuda') }}
        ENABLE_MPI: ${{ contains(matrix.config, 'mpi') }}
        ENABLE_TBB: ${{ contains(matrix.config, 'tbb') }}
        ENABLE_LLVM: ${{ contains(matrix.config, 'llvm') }}
        BUILD_MD: ${{ !contains(matrix.config, 'nomd') }}
        BUILD_HPMC: ${{ !contains(matrix.config, 'nohpmc') }}
        BUILD_DEBUG: ${{ contains(matrix.config, 'debug') }}
      shell: bash
    - name: Build
      run: ninja install -j $(($(getconf _NPROCESSORS_ONLN) + 2))
      working-directory: build
    - name: Configure plugins
      run : |
        mkdir -p build-example-plugins
        cd build-example-plugins
        if [[ ${BUILD_DEBUG} == "true" ]]; then BUILD_TYPE="Debug"; else BUILD_TYPE="Release"; fi
        echo "BUILD_TYPE=${BUILD_TYPE}"
        CMAKE_PREFIX_PATH=${GITHUB_WORKSPACE}/install cmake ../code/example_plugins -GNinja -DCMAKE_BUILD_TYPE=${BUILD_TYPE}
      env:
        BUILD_DEBUG: ${{ contains(matrix.config, 'debug') }}
      shell: bash
    - name: Build plugins
      run: ninja install -j $(($(getconf _NPROCESSORS_ONLN) + 2))
      working-directory: build-example-plugins

    - name: Remove object files
      run: find build -type f -name '*.o' -delete
    # Tar the build directory to preserve permissions and reduce HTTP requests on upload.
    - name: 'Tar build'
      run: tar --use-compress-program='zstd -10 -T0' -cvf build.tar build
    - name: 'Tar install'
      run: tar --use-compress-program='zstd -10 -T0' -cvf install.tar install
    # Upload the tarballs. Retain the file for a limited time in case developers need to download
    # and run tests locally for further debugging.
    - name: 'Upload build'
      uses: actions/upload-artifact@v3.1.2
      with:
        name: build-${{ join(matrix.config, '_') }}-${{ github.sha }}
        path: build.tar
        retention-days: 7
    - name: 'Upload install'
      uses: actions/upload-artifact@v3.1.2
      with:
        name: install-${{ join(matrix.config, '_') }}-${{ github.sha }}
        path: install.tar
        retention-days: 7

    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Clean HOME
      run: ( shopt -s dotglob nullglob; rm -rf $HOME/* )
      shell: bash


  pytest:
    name: Run pytest [${{ join(matrix.config, '_') }}]
    needs: build
    runs-on: ${{ matrix.test_runner }}
    container:
      image: glotzerlab/ci:2023.05-${{ matrix.config[0] }}
      options: ${{ matrix.test_docker_options }} -e CUDA_VISIBLE_DEVICES
    strategy:
      matrix:
        include:
        - {config: [clang14_py311, mpi, tbb, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nomd], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nohpmc], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nomd, nohpmc], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [cuda120_gcc11_py310, mpi, llvm, debug], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda120_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda120_gcc11_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [gcc9_py39], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }

    steps:
    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Checkout
      uses: actions/checkout@v3.5.2
      with:
        path: code
        submodules: true

    - name: Download install
      uses: actions/download-artifact@v3.0.2
      with:
        name: install-${{ join(matrix.config, '_') }}-${{ github.sha }}
    - name: Untar install
      run: tar --use-compress-program='zstd -10 -T0' -xvf install.tar

    - name: Run pytest (serial)
      run: python3 -m pytest --pyargs hoomd -v -ra --durations=0 --durations-min=0.1
    - name: Run pytest (mpi)
      if: ${{ contains(matrix.config, 'mpi') }}
      run: mpirun -n 2 ${GITHUB_WORKSPACE}/install/hoomd/pytest/pytest-openmpi.sh -x --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 || (( cat pytest.out.1 && exit 1 ))
    - name: Run pytest (serial without cupy)
      if: ${{ contains(matrix.config[0], 'cuda') }}
      run: python3 -m pytest --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 -m cupy_optional
      env:
        _HOOMD_DISALLOW_CUPY_: 1
    - name: Run pytest (mpi without cupy)
      if: ${{ contains(matrix.config[0], 'cuda') && contains(matrix.config, 'mpi') }}
      run: mpirun -n 2 ${GITHUB_WORKSPACE}/install/hoomd/pytest/pytest-openmpi.sh -x --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 -m cupy_optional || (( cat pytest.out.1 && exit 1 ))
      env:
        _HOOMD_DISALLOW_CUPY_: 1

    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Clean HOME
      run: ( shopt -s dotglob nullglob; rm -rf $HOME/* )
      shell: bash


  ctest:
    name: Run ctest [${{ join(matrix.config, '_') }}]
    needs: build
    runs-on: ${{ matrix.test_runner }}
    container:
      image: glotzerlab/ci:2023.05-${{ matrix.config[0] }}
      options: ${{ matrix.test_docker_options }} -e CUDA_VISIBLE_DEVICES
    strategy:
      matrix:
        include:
        - {config: [clang14_py311, mpi, tbb, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nomd], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nohpmc], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311, nomd, nohpmc], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [cuda120_gcc11_py310, mpi, llvm, debug], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda120_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda120_gcc11_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [gcc9_py39], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }

    steps:
    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Checkout
      uses: actions/checkout@v3.5.2
      with:
        path: code
        submodules: true

    - name: Download build
      uses: actions/download-artifact@v3.0.2
      with:
        name: build-${{ join(matrix.config, '_') }}-${{ github.sha }}
    - name: Untar build
      run: tar --use-compress-program='zstd -10 -T0' -xvf build.tar

    - name: Run tests
      run: >-
        ctest
        -T test
        --output-on-failure
        --test-output-size-failed 1048576
        --test-output-size-passed 1048576
      working-directory: build

    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Clean HOME
      run: ( shopt -s dotglob nullglob; rm -rf $HOME/* )
      shell: bash


  validate:
    name: Validate [${{ join(matrix.config, '_') }}]
    needs: build
    runs-on: ${{ matrix.test_runner }}
    container:
      image: glotzerlab/ci:2023.05-${{ matrix.config[0] }}
      options: ${{ matrix.test_docker_options }} -e CUDA_VISIBLE_DEVICES
    strategy:
      matrix:
        include:
        - {config: [clang14_py311, mpi, tbb, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc12_py311], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [cuda120_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda120_gcc11_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }

    if: ${{ contains(github.event.pull_request.labels.*.name, 'validate') }}
    steps:
    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Checkout
      uses: actions/checkout@v3.5.2
      with:
        path: code
        submodules: true

    - name: Download install
      uses: actions/download-artifact@v3.0.2
      with:
        name: install-${{ join(matrix.config, '_') }}-${{ github.sha }}
    - name: Untar install
      run: tar --use-compress-program='zstd -10 -T0' -xvf install.tar

    - name: Run pytest (serial)
      if: ${{ !contains(matrix.config, 'mpi') }}
      run: python3 -m pytest --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 -p hoomd.pytest_plugin_validate -m validate --validate
    - name: Run pytest (mpi)
      if: ${{ contains(matrix.config, 'mpi') }}
      run: mpirun -n 2 ${GITHUB_WORKSPACE}/install/hoomd/pytest/pytest-openmpi.sh -x --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 -p hoomd.pytest_plugin_validate -m validate --validate || (( cat pytest.out.1 && exit 1 ))
    - name: Run howto guides (serial)
      if: ${{ contains(matrix.config, 'llvm') }}  # some examples require LLVM
      run: 'for i in *.py; do echo "Running howto: $i" && python3 $i || exit 1; done'
      working-directory: code/sphinx-doc/howto

    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Clean HOME
      run: ( shopt -s dotglob nullglob; rm -rf $HOME/* )
      shell: bash


  build_release:
    name: Build [${{ join(matrix.config, '_') }}]
    runs-on: ${{ matrix.build_runner }}
    container:
      image: glotzerlab/ci:2023.05-${{ matrix.config[0] }}
    strategy:
      matrix:
        include:
        - {config: [clang13_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [clang12_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [clang11_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc11_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc10_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [cuda118_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda117_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda116_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda115_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda114_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda113_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda112_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda111_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [clang10_py38, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }

    if: ${{ contains(github.event.pull_request.labels.*.name, 'release') }}
    steps:
    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Checkout
      uses: actions/checkout@v3.5.2
      with:
        path: code
        submodules: true

    - name: Configure
      run: |
        mkdir -p build
        cd build
        if [[ ${BUILD_DEBUG} == "true" ]]; then BUILD_TYPE="Debug"; else BUILD_TYPE="Release"; fi
        echo "BUILD_TYPE=${BUILD_TYPE}"
        cmake ../code -GNinja \
                      -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \
                      -DENABLE_GPU=${ENABLE_GPU:-"OFF"} \
                      -DENABLE_MPI=${ENABLE_MPI:-"OFF"} \
                      -DENABLE_TBB=${ENABLE_TBB:-"OFF"} \
                      -DENABLE_LLVM=${ENABLE_LLVM:-"OFF"} \
                      -DBUILD_MD=${BUILD_MD:-"ON"} \
                      -DBUILD_MPCD=${BUILD_MD:-"ON"} \
                      -DBUILD_METAL=${BUILD_MD:-"ON"} \
                      -DBUILD_HPMC=${BUILD_HPMC:-"ON"} \
                      -DCUDA_ARCH_LIST="60;70" \
                      -DENABLE_DEBUG_JIT=ON \
                      -DCMAKE_INSTALL_PREFIX=${GITHUB_WORKSPACE}/install \
                      -DPLUGINS=""
      env:
        ENABLE_GPU: ${{ contains(matrix.config[0], 'cuda') }}
        ENABLE_MPI: ${{ contains(matrix.config, 'mpi') }}
        ENABLE_TBB: ${{ contains(matrix.config, 'tbb') }}
        ENABLE_LLVM: ${{ contains(matrix.config, 'llvm') }}
        BUILD_MD: ${{ !contains(matrix.config, 'nomd') }}
        BUILD_HPMC: ${{ !contains(matrix.config, 'nohpmc') }}
        BUILD_DEBUG: ${{ contains(matrix.config, 'debug') }}
      shell: bash
    - name: Build
      run: ninja install -j $(($(getconf _NPROCESSORS_ONLN) + 2))
      working-directory: build
    - name: Configure plugins
      run : |
        mkdir -p build-example-plugins
        cd build-example-plugins
        if [[ ${BUILD_DEBUG} == "true" ]]; then BUILD_TYPE="Debug"; else BUILD_TYPE="Release"; fi
        echo "BUILD_TYPE=${BUILD_TYPE}"
        CMAKE_PREFIX_PATH=${GITHUB_WORKSPACE}/install cmake ../code/example_plugins -GNinja -DCMAKE_BUILD_TYPE=${BUILD_TYPE}
      env:
        BUILD_DEBUG: ${{ contains(matrix.config, 'debug') }}
      shell: bash
    - name: Build plugins
      run: ninja install -j $(($(getconf _NPROCESSORS_ONLN) + 2))
      working-directory: build-example-plugins

    - name: Remove object files
      run: find build -type f -name '*.o' -delete
    # Tar the build directory to preserve permissions and reduce HTTP requests on upload.
    - name: 'Tar build'
      run: tar --use-compress-program='zstd -10 -T0' -cvf build.tar build
    - name: 'Tar install'
      run: tar --use-compress-program='zstd -10 -T0' -cvf install.tar install
    # Upload the tarballs. Retain the file for a limited time in case developers need to download
    # and run tests locally for further debugging.
    - name: 'Upload build'
      uses: actions/upload-artifact@v3.1.2
      with:
        name: build-${{ join(matrix.config, '_') }}-${{ github.sha }}
        path: build.tar
        retention-days: 7
    - name: 'Upload install'
      uses: actions/upload-artifact@v3.1.2
      with:
        name: install-${{ join(matrix.config, '_') }}-${{ github.sha }}
        path: install.tar
        retention-days: 7

    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Clean HOME
      run: ( shopt -s dotglob nullglob; rm -rf $HOME/* )
      shell: bash


  pytest_release:
    name: Run pytest [${{ join(matrix.config, '_') }}]
    needs: build_release
    runs-on: ${{ matrix.test_runner }}
    container:
      image: glotzerlab/ci:2023.05-${{ matrix.config[0] }}
      options: ${{ matrix.test_docker_options }} -e CUDA_VISIBLE_DEVICES
    strategy:
      matrix:
        include:
        - {config: [clang13_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [clang12_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [clang11_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc11_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc10_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [cuda118_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda117_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda116_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda115_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda114_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda113_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda112_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda111_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [clang10_py38, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }

    if: ${{ contains(github.event.pull_request.labels.*.name, 'release') }}
    steps:
    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Checkout
      uses: actions/checkout@v3.5.2
      with:
        path: code
        submodules: true

    - name: Download install
      uses: actions/download-artifact@v3.0.2
      with:
        name: install-${{ join(matrix.config, '_') }}-${{ github.sha }}
    - name: Untar install
      run: tar --use-compress-program='zstd -10 -T0' -xvf install.tar

    - name: Run pytest (serial)
      run: python3 -m pytest --pyargs hoomd -v -ra --durations=0 --durations-min=0.1
    - name: Run pytest (mpi)
      if: ${{ contains(matrix.config, 'mpi') }}
      run: mpirun -n 2 ${GITHUB_WORKSPACE}/install/hoomd/pytest/pytest-openmpi.sh -x --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 || (( cat pytest.out.1 && exit 1 ))
    - name: Run pytest (serial without cupy)
      if: ${{ contains(matrix.config[0], 'cuda') }}
      run: python3 -m pytest --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 -m cupy_optional
      env:
        _HOOMD_DISALLOW_CUPY_: 1
    - name: Run pytest (mpi without cupy)
      if: ${{ contains(matrix.config[0], 'cuda') && contains(matrix.config, 'mpi') }}
      run: mpirun -n 2 ${GITHUB_WORKSPACE}/install/hoomd/pytest/pytest-openmpi.sh -x --pyargs hoomd -v -ra --durations=0 --durations-min=0.1 -m cupy_optional || (( cat pytest.out.1 && exit 1 ))
      env:
        _HOOMD_DISALLOW_CUPY_: 1

    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Clean HOME
      run: ( shopt -s dotglob nullglob; rm -rf $HOME/* )
      shell: bash


  ctest_release:
    name: Run ctest [${{ join(matrix.config, '_') }}]
    needs: build_release
    runs-on: ${{ matrix.test_runner }}
    container:
      image: glotzerlab/ci:2023.05-${{ matrix.config[0] }}
      options: ${{ matrix.test_docker_options }} -e CUDA_VISIBLE_DEVICES
    strategy:
      matrix:
        include:
        - {config: [clang13_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [clang12_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [clang11_py310, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc11_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [gcc10_py310], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }
        - {config: [cuda118_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda117_gcc11_py310, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda116_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda115_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda114_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda113_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda112_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [cuda111_gcc9_py38, mpi, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: [self-hosted,GPU], test_docker_options: '--gpus=all --device /dev/nvidia0 --device /dev/nvidia1 --device /dev/nvidia-uvm --device /dev/nvidia-uvm-tools --device /dev/nvidiactl' }
        - {config: [clang10_py38, llvm], build_runner: [self-hosted,jetstream2,CPU], test_runner: ubuntu-latest, test_docker_options: '' }

    if: ${{ contains(github.event.pull_request.labels.*.name, 'release') }}
    steps:
    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Checkout
      uses: actions/checkout@v3.5.2
      with:
        path: code
        submodules: true

    - name: Download build
      uses: actions/download-artifact@v3.0.2
      with:
        name: build-${{ join(matrix.config, '_') }}-${{ github.sha }}
    - name: Untar build
      run: tar --use-compress-program='zstd -10 -T0' -xvf build.tar

    - name: Run tests
      run: >-
        ctest
        -T test
        --output-on-failure
        --test-output-size-failed 1048576
        --test-output-size-passed 1048576
      working-directory: build

    - name: Clean workspace
      run: ( shopt -s dotglob nullglob; rm -rf ./* )
      shell: bash
    - name: Clean HOME
      run: ( shopt -s dotglob nullglob; rm -rf $HOME/* )
      shell: bash


  # This job is used to provide a single requirement for branch merge conditions. GitHub considers
  # the check passing even if it is skipped, so this job raises errors when required jobs were not
  # run.
  unit_tests_complete:
    name: Unit test
    needs: [pytest, ctest, validate]
    if: ${{ always() && github.event_name == 'pull_request' }}
    runs-on: ubuntu-latest

    steps:
      - name: Error if pytest did not succeed
        if: needs.pytest.result != 'success'
        run: echo "::error ::pytest tests failed." && exit 1
      - name: Error if ctest did not succeed
        if: needs.ctest.result != 'success'
        run: echo "::error ::ctest tests failed." && exit 1
      - name: Warn if validate did not run
        if: needs.validate.result == 'skipped'
        run: echo "::warning ::Skipped validation tests." && exit 1
      - name: Error if validate did not succeed
        if: needs.validate.result != 'success'
        run: echo "::error ::Validation tests failed." && exit 1
      - run: echo "Done!"
